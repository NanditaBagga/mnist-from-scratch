{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\nandita\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.23.5)\n",
      "Requirement already satisfied: requests in c:\\users\\nandita\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nandita\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nandita\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\nandita\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nandita\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests) (3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "!pip install numpy requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import random\n",
    "import time\n",
    "import struct\n",
    "import requests\n",
    "import os\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist_data(filename):\n",
    "    print('downloading', filename)\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    r = requests.get('http://yann.lecun.com/exdb/mnist/' + filename)\n",
    "    if r.status_code != 200:\n",
    "        return False\n",
    "    open('data/' + filename, 'wb').write(r.content)\n",
    "    return True\n",
    "\n",
    "def decompress_mnist_data(filename):\n",
    "    print('decompressing', filename)\n",
    "    with gzip.open(f'data/{filename}', 'rb') as fc:\n",
    "        with open(f\"data/{filename.split('.')[0]}\", 'wb') as fd:\n",
    "            fd.write(fc.read())\n",
    "    return True\n",
    "\n",
    "def get_mnist_data():\n",
    "    filenames = [\n",
    "        'train-images-idx3-ubyte.gz',\n",
    "        'train-labels-idx1-ubyte.gz',\n",
    "        't10k-images-idx3-ubyte.gz',\n",
    "        't10k-labels-idx1-ubyte.gz'\n",
    "    ]\n",
    "    for filename in filenames:\n",
    "        if os.path.exists(f'data/{filename}') or download_mnist_data(filename):\n",
    "            if not os.path.exists(f\"data/{filename.split('.')[0]}\"):\n",
    "                decompress_mnist_data(filename)\n",
    "        else:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def read(dataset= 'training', path= './data'):\n",
    "    if dataset == 'training':\n",
    "        fname_img = path + '/train-images-idx3-ubyte'\n",
    "        fname_lbl = path + '/train-labels-idx1-ubyte'\n",
    "    elif dataset == 'testing':\n",
    "        fname_img = path + '/t10k-images-idx3-ubyte'\n",
    "        fname_lbl = path + '/t10k-labels-idx1-ubyte'\n",
    "    else:\n",
    "        raise ValueError('dataset must be \\'testing\\' or \\'training\\'')\n",
    "    flbl = open(fname_lbl, 'rb')\n",
    "    magic_no, size = struct.unpack('>II', flbl.read(8))\n",
    "    if magic_no != 2049:\n",
    "        raise RuntimeError('Invalid MNIST ' + dataset + ' label file')\n",
    "    fimg = open(fname_img, 'rb')\n",
    "    magic_no, size, rows, cols = struct.unpack('>IIII', fimg.read(16))\n",
    "    if magic_no != 2051:\n",
    "        raise RuntimeError('Invalid MNIST ' + dataset + ' image file')\n",
    "    img_size = rows * cols\n",
    "    data = []\n",
    "    for lbl in flbl.read():\n",
    "        x = numpy.frombuffer(fimg.read(img_size), dtype=numpy.uint8).astype(numpy.float64) / 255\n",
    "        y = numpy.zeros(10)\n",
    "        y[lbl] = 1\n",
    "        data.append([x.reshape((1, img_size)), y.reshape((1, 10))])\n",
    "    flbl.close()\n",
    "    fimg.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1.0+numpy.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z)*(1-sigmoid(z))\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, inp_size, out_size, ETA):\n",
    "        self.ETA = ETA\n",
    "        self.b = numpy.random.randn(1, out_size)\n",
    "        self.w = numpy.random.randn(inp_size, out_size)\n",
    "        self.bgrad = 0.0\n",
    "        self.wgrad = 0.0\n",
    "    def forward(self, inp):\n",
    "        self.x = inp\n",
    "        self.y = numpy.dot(self.x, self.w) + self.b\n",
    "        self.a = sigmoid(self.y)\n",
    "        return self.a\n",
    "    def compgrad(self, a_grad):\n",
    "        y_grad = sigmoid_prime(self.y) * a_grad\n",
    "        self.bgrad += y_grad\n",
    "        self.wgrad += numpy.dot(self.x.T, y_grad)\n",
    "        return numpy.dot(y_grad, self.w.T)\n",
    "    def backprop(self):\n",
    "        self.w -= self.ETA * self.wgrad\n",
    "        self.b -= self.ETA * self.bgrad\n",
    "        self.bgrad = 0\n",
    "        self.wgrad = 0\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, net_size, ETA):\n",
    "        self.layers = []\n",
    "        for i in range(len(net_size) - 1):\n",
    "            self.layers.append(Layer(net_size[i], net_size[i + 1], ETA))\n",
    "    def forward(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l.forward(x)\n",
    "        return x\n",
    "    def compgrad(self, a_grad):\n",
    "        for l in reversed(self.layers):\n",
    "            a_grad = l.compgrad(a_grad)\n",
    "    def backprop(self):\n",
    "        for l in reversed(self.layers):\n",
    "            l.backprop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(traindata, BATCH_SIZE= 10):\n",
    "    data_size = len(traindata)\n",
    "    random.shuffle(traindata)\n",
    "    batches = (traindata[i : i + BATCH_SIZE] for i in range(0, data_size, BATCH_SIZE))\n",
    "    loss = 0.0\n",
    "    for batch in batches:\n",
    "        for x, y in batch:\n",
    "            a = network.forward(x)\n",
    "            loss += (a - y) ** 2 / BATCH_SIZE\n",
    "            a_grad = 2 * (a - y) / BATCH_SIZE\n",
    "            network.compgrad(a_grad)\n",
    "        network.backprop()\n",
    "    return numpy.sum(loss) * BATCH_SIZE / data_size\n",
    "\n",
    "def test(testdata):\n",
    "    correct = 0\n",
    "    for x,y in testdata:\n",
    "        n = network.forward(x)\n",
    "        if numpy.array_equal(numpy.around(n), y):\n",
    "            correct += 1\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading train-images-idx3-ubyte.gz\n",
      "decompressing train-images-idx3-ubyte.gz\n",
      "downloading train-labels-idx1-ubyte.gz\n",
      "decompressing train-labels-idx1-ubyte.gz\n",
      "downloading t10k-images-idx3-ubyte.gz\n",
      "decompressing t10k-images-idx3-ubyte.gz\n",
      "downloading t10k-labels-idx1-ubyte.gz\n",
      "decompressing t10k-labels-idx1-ubyte.gz\n",
      "Training and Testing every Epoch . . .\n",
      "Loss: 0.3521632176848737 Epoch: 0 ( 7740 / 10000 )\n",
      "Loss: 0.2238881231528537 Epoch: 1 ( 8022 / 10000 )\n",
      "Loss: 0.20162379935473382 Epoch: 2 ( 8119 / 10000 )\n",
      "Loss: 0.18875946547917125 Epoch: 3 ( 8101 / 10000 )\n",
      "Loss: 0.18131942397469747 Epoch: 4 ( 8232 / 10000 )\n",
      "Loss: 0.09761080332963741 Epoch: 5 ( 9125 / 10000 )\n",
      "Loss: 0.079473300512643 Epoch: 6 ( 9211 / 10000 )\n",
      "Loss: 0.07431529957033955 Epoch: 7 ( 9250 / 10000 )\n",
      "Loss: 0.07116700877644976 Epoch: 8 ( 9193 / 10000 )\n",
      "Loss: 0.06782681374012968 Epoch: 9 ( 9257 / 10000 )\n",
      "Loss: 0.06516632454401132 Epoch: 10 ( 9281 / 10000 )\n",
      "Loss: 0.06327091859075568 Epoch: 11 ( 9277 / 10000 )\n",
      "Loss: 0.061413038002076134 Epoch: 12 ( 9298 / 10000 )\n",
      "Loss: 0.0591536876475421 Epoch: 13 ( 9230 / 10000 )\n",
      "Loss: 0.057454345477800504 Epoch: 14 ( 9281 / 10000 )\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "BATCH_SIZE = 10\n",
    "ETA = 1.5\n",
    "if get_mnist_data():\n",
    "    print('Training and Testing every Epoch . . .')\n",
    "    traindata = read()\n",
    "    testdata = read(dataset='testing')\n",
    "    network = Model([784, 39, 10], ETA)\n",
    "    for itr in range(EPOCHS):\n",
    "        print(f'Loss: {train(traindata, BATCH_SIZE)} Epoch: {itr} ( {test(testdata)} / {len(testdata)} )')\n",
    "else:\n",
    "    print('Unable to download MNIST dataset')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1e0f1c99eed810b37474cf421a65240bb9c344dac0ae2d8bd67bc67b819b611d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
